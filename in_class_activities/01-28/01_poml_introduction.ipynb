{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 1: Introduction to POML\n",
    "\n",
    "**Prompt Orchestration Markup Language**\n",
    "\n",
    "Based on:\n",
    "- https://betterstack.com/community/guides/ai/poml-markup/\n",
    "- https://microsoft.github.io/poml/stable/\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand why structured prompts matter for maintainability\n",
    "- Write basic POML prompts using core tags\n",
    "- Use POML templates with variables and Python context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "First, let's install the required packages and set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install poml langchain==1.2.7 langchain-groq python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from poml import poml\n",
    "\n",
    "# Load environment variables (for API keys later)\n",
    "load_dotenv()\n",
    "\n",
    "# Set up Groq API key\n",
    "if not os.getenv('GROQ_API_KEY'):\n",
    "    os.environ['GROQ_API_KEY'] = input('Enter your Groq API key: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Why POML?\n",
    "\n",
    "### The Problem with Plain Text Prompts\n",
    "\n",
    "As AI applications become more sophisticated, prompts can quickly become:\n",
    "- **Hard to read**: Long strings with instructions, examples, and data mixed together\n",
    "- **Hard to maintain**: Changes require finding and updating text in multiple places\n",
    "- **Hard to reuse**: Copy-pasting leads to inconsistencies\n",
    "\n",
    "### Example: A Standard Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is how prompts often look in real applications - messy!\n",
    "standard_prompt = \"\"\"\n",
    "You are an expert at explaining complex topics.\n",
    "Explain this machine learning.\n",
    "Aim for an advanced level of explanation depth.\n",
    "\"\"\"\n",
    "\n",
    "print(standard_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Issues with this are that all the information is hardcoded into the prompt and that all types of information are mixe together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POML Solution\n",
    "\n",
    "POML (Prompt Orchestration Markup Language) brings structure to prompts using an HTML-like syntax with semantic tags:\n",
    "\n",
    "| Tag | Purpose |\n",
    "|-----|--------|\n",
    "| `<role>` | Define the AI's persona/system message |\n",
    "| `<task>` | Specify the main objective |\n",
    "| `<hint>` | Provide additional guidance |\n",
    "| `<example>` | Include few-shot examples |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. POML Basics\n",
    "\n",
    "### Your First POML Prompt\n",
    "\n",
    "Let's rewrite that messy prompt using POML:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poml_prompt = \"\"\"\n",
    "<poml>\n",
    "  <role>You are an expert at explaining complex topics.</role>\n",
    "  <task>Explain this topic: {{topic}}</task>\n",
    "  <hint>Aim for this level of explanation depth: {{explanation_depth}}</hint>\n",
    "</poml>\n",
    "\"\"\"\n",
    "\n",
    "# The context is a dictionary passed to the poml function\n",
    "# The keys in the dictionary become available as variables inside the .poml file\n",
    "context = {\n",
    "    'topic': 'machine_learning',\n",
    "    'explanation_depth': 'advanced'\n",
    "}\n",
    "\n",
    "output = poml(poml_prompt, context)\n",
    "print(output[0]['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Benefits\n",
    "\n",
    "1. **Structure is visible**: Tags clearly separate role, task, hints, and content\n",
    "2. **Self-documenting**: The markup explains what each part does\n",
    "3. **Easy to modify**: Change one section without affecting others"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling to Different Formats\n",
    "\n",
    "POML can output different formats using the `syntax` attribute:\n",
    "\n",
    "Supported formats: markdown, html, json, yaml, xml, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile to JSON format\n",
    "json_prompt = \"\"\"\n",
    "<poml syntax=\"json\">\n",
    "  <role>You are a code reviewer.</role>\n",
    "  <task>Review the provided code for bugs.</task>\n",
    "  <hint>Focus on logic errors, not style.</hint>\n",
    "</poml>\n",
    "\"\"\"\n",
    "\n",
    "result = poml(json_prompt)\n",
    "print(\"JSON output:\")\n",
    "print(result[0]['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Templates and Variables\n",
    "\n",
    "POML's real power comes from its template engine. You can use:\n",
    "- **Variables**: `{{variable_name}}` for dynamic content\n",
    "- **`<let>`**: Define variables within the template\n",
    "- **`if`**: Conditional content\n",
    "- **`for`**: Loop over lists\n",
    "\n",
    "### Using Variables with Python Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a template with variables\n",
    "template_prompt = \"\"\"\n",
    "<poml>\n",
    "  <role>You are a helpful {{role_type}} assistant.</role>\n",
    "  <task>Explain {{topic}} to a {{audience}} audience.</task>\n",
    "  <hint>Keep it {{style}}.</hint>\n",
    "</poml>\n",
    "\"\"\"\n",
    "\n",
    "# Pass context from Python\n",
    "context = {\n",
    "    \"role_type\": \"technical\",\n",
    "    \"topic\": \"neural networks\",\n",
    "    \"audience\": \"beginner\",\n",
    "    \"style\": \"concise with examples\"\n",
    "}\n",
    "\n",
    "result = poml(template_prompt, context)\n",
    "print(\"Dynamic prompt:\")\n",
    "print(result[0]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try with different context - same template, different output!\n",
    "context_advanced = {\n",
    "    \"role_type\": \"academic\",\n",
    "    \"topic\": \"transformer architecture\",\n",
    "    \"audience\": \"graduate student\",\n",
    "    \"style\": \"detailed with mathematical notation\"\n",
    "}\n",
    "\n",
    "result = poml(template_prompt, context_advanced)\n",
    "print(\"Same template, different context:\")\n",
    "print(result[0]['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditionals with `if`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conditional content based on context\n",
    "conditional_prompt = \"\"\"\n",
    "<poml>\n",
    "  <role>You are a helpful assistant.</role>\n",
    "  <task>Answer the user's question about {{topic}}.</task>\n",
    "  \n",
    "  <hint if=\"include_examples\">Include 2-3 concrete examples.</hint>\n",
    "  <hint if=\"keep_short\">Keep your response under 100 words.</hint>\n",
    "</poml>\n",
    "\"\"\"\n",
    "\n",
    "# Context with examples enabled, short disabled\n",
    "context = {\n",
    "    \"topic\": \"Python loops\",\n",
    "    \"include_examples\": True,\n",
    "    \"keep_short\": False\n",
    "}\n",
    "\n",
    "result = poml(conditional_prompt, context)\n",
    "print(\"With examples, no length limit:\")\n",
    "print(result[0]['content'])\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "\n",
    "# Now flip the conditions\n",
    "context[\"include_examples\"] = False\n",
    "context[\"keep_short\"] = True\n",
    "\n",
    "result = poml(conditional_prompt, context)\n",
    "print(\"No examples, keep short:\")\n",
    "print(result[0]['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over a list of items\n",
    "loop_prompt = \"\"\"\n",
    "<poml>\n",
    "  <role>You are a quiz generator.</role>\n",
    "  <task>Create a multiple choice question for each of the following topics:</task>\n",
    "  \n",
    "  <list>\n",
    "    <item for=\"topic in topics\">{{topic}}</item>\n",
    "  </list>\n",
    "</poml>\n",
    "\"\"\"\n",
    "\n",
    "context = {\n",
    "    \"topics\": [\"Machine Learning\", \"Neural Networks\", \"Natural Language Processing\"]\n",
    "}\n",
    "\n",
    "result = poml(loop_prompt, context)\n",
    "print(\"Loop output:\")\n",
    "print(result[0]['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Using POML with LangChain and Groq\n",
    "\n",
    "Let's put it all together and actually call an LLM with our POML prompt!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Initialize the Groq LLM\n",
    "llm = ChatGroq(model=\"openai/gpt-oss-20b\", temperature=0.7)\n",
    "\n",
    "# Create a POML prompt\n",
    "explanation_prompt = \"\"\"\n",
    "<poml>\n",
    "  <role>You are a friendly teacher who excels at explaining complex topics simply.</role>\n",
    "  <task>Explain {{topic}} in 2-3 sentences.</task>\n",
    "  <hint>Use an analogy if it helps.</hint>\n",
    "</poml>\n",
    "\"\"\"\n",
    "\n",
    "# Compile with context\n",
    "context = {\"topic\": \"how neural networks learn\"}\n",
    "compiled = poml(explanation_prompt, context)\n",
    "\n",
    "# Send to the LLM\n",
    "response = llm.invoke([HumanMessage(content=compiled[0]['content'])])\n",
    "print(\"LLM Response:\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Quick Exercise\n",
    "\n",
    "**Your turn!** Create a POML prompt that:\n",
    "1. Takes a `topic` variable\n",
    "2. Has a role as an \"expert educator\"\n",
    "3. Tasks the AI with creating a brief explanation\n",
    "4. Includes a conditional hint for `include_quiz` that adds \"End with a simple quiz question\"\n",
    "\n",
    "Test it with `topic=\"recursion\"` and `include_quiz=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# Create your POML prompt template\n",
    "my_prompt = \"\"\"\n",
    "<poml>\n",
    "  <!-- Add your role, task, and conditional hint here -->\n",
    "</poml>\n",
    "\"\"\"\n",
    "\n",
    "# Define context\n",
    "my_context = {\n",
    "    \"topic\": \"recursion\",\n",
    "    \"include_quiz\": True\n",
    "}\n",
    "\n",
    "# Compile and print\n",
    "result = poml(my_prompt, my_context)\n",
    "print(result[0]['content'])\n",
    "\n",
    "# Send to LLM\n",
    "response = llm.invoke([HumanMessage(content=result[0]['content'])])\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, you learned:\n",
    "\n",
    "1. **Why POML matters**: Structured prompts are more maintainable and reusable\n",
    "2. **Core tags**: `<role>`, `<task>`, `<hint>` for semantic structure\n",
    "3. **Templates**: Variables (`{{}}`), conditionals (`if`), and loops (`for`)\n",
    "4. **Python integration**: Passing context dictionaries to POML templates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
